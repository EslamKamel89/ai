import json
import re
import uuid
import chromadb
from chromadb.utils import embedding_functions
from langchain.text_splitter import RecursiveCharacterTextSplitter

# âœï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙ‚Ø·ÙŠØ¹
CHUNK_SIZE = 600
CHUNK_OVERLAP = 75

# ğŸ§¹ ØªÙ†Ø¸ÙŠÙ HTML Ùˆ CSS Ùˆ JavaScript
def clean_html(raw_html):
    if not isinstance(raw_html, str):
        raw_html = ""
    raw_html = re.sub(r'<script.*?>.*?</script>', '', raw_html, flags=re.DOTALL)
    raw_html = re.sub(r'<style.*?>.*?</style>', '', raw_html, flags=re.DOTALL)
    raw_html = re.sub(r'<[^>]+>', '', raw_html)
    raw_html = re.sub(r'\s+', ' ', raw_html).strip()
    return raw_html

# ğŸ§  Ø¥Ø¹Ø¯Ø§Ø¯ Chroma
chroma_client = chromadb.PersistentClient(path="./chroma_db")
embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

collection = chroma_client.get_or_create_collection(
    name="quran",
    embedding_function=embedding_fn
)

# ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù JSON
with open("data/quran.json", "r", encoding="utf-8") as f:
    data = json.load(f)

# ğŸª“ Ø£Ø¯Ø§Ø© Ø§Ù„ØªÙ‚Ø·ÙŠØ¹
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=CHUNK_SIZE,
    chunk_overlap=CHUNK_OVERLAP
)

# â›“ï¸ ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
ids = []
documents = []
metadatas = []

for item in data:
    explain_raw = item.get("explain_ar", "")
    if not explain_raw:
        continue

    cleaned_text = clean_html(explain_raw)
    chunks = text_splitter.create_documents([cleaned_text])

    sura_id = item.get("sura_id", "unknown")
    ayah = item.get("ayah", "unknown")

    for i, chunk in enumerate(chunks):
        unique_id = uuid.uuid4().hex[:8] if "unknown" in (str(sura_id), str(ayah)) else str(i)
        doc_id = f"{sura_id}_{ayah}_{unique_id}"

        ids.append(doc_id)
        documents.append(chunk.page_content)
        metadatas.append({
            "sura_id": sura_id,
            "ayah": ayah,
            "text_ar": item.get("text_ar", ""),
            "sura_ar": item.get("sura_ar", "")
        })

        print(f"ğŸ“¥ ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ù‚Ø·Ø¹ {i+1} Ù…Ù† Ø§Ù„Ø¢ÙŠØ© {ayah} (Ø§Ù„Ø³ÙˆØ±Ø© {sura_id}) | ÙƒÙ„Ù…Ø§Øª: {len(chunk.page_content.split())}")

# ğŸ§¾ Ø¥Ø¯Ø®Ø§Ù„ ÙÙŠ Chroma
collection.add(
    ids=ids,
    documents=documents,
    metadatas=metadatas
)

print(f"\nâœ… ØªÙ… Ø¥Ø¯Ø®Ø§Ù„ {len(documents)} Ù…Ù‚Ø·Ø¹Ù‹Ø§ ÙÙŠ Chroma DB Ø¨Ù†Ø¬Ø§Ø­.")
